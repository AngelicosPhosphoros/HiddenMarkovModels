{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Program HMM Timur Khuzin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that read parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All lines started with `#` are ignored\n",
    "\n",
    "First line of file: M,K,L tab separated<br>\n",
    "Than M lines of M numbers (MxM transition matrix)<br>\n",
    "Row index is old state, column index is next state<br>\n",
    "Than M lines of K numbers (MxK emisstion matrix)<br>\n",
    "Each row of emission matrix is probabilities of K emissions.<br>\n",
    "Than M numbers in line (Vector of M â€” initial distribution)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class HMM_Params:\n",
    "    def __init__(self, state_num, emission_num, to_observe):\n",
    "        self.state_num = state_num\n",
    "        self.emission_num = emission_num\n",
    "        self.observation_length = to_observe\n",
    "        self.transition_matrix = np.zeros((state_num, state_num), dtype='float64')\n",
    "        self.emission_matrix = np.zeros((state_num, emission_num), dtype='float64')\n",
    "        self.beginning_distribution = np.zeros((state_num), dtype='float64')\n",
    "\n",
    "def read_params(filename):\n",
    "    def read_non_comment(f):\n",
    "        s = f.readline()\n",
    "        while(s[0]=='#'):\n",
    "            s = f.readline()\n",
    "        return s\n",
    "    with open(filename, 'r') as f:\n",
    "        M, K, L = map(int, read_non_comment(f).strip().split())\n",
    "        params = HMM_Params(M, K, L)\n",
    "        \n",
    "        for i in range(M):\n",
    "            params.transition_matrix[i,:] = [float(x) for x in read_non_comment(f).strip().split()]\n",
    "            \n",
    "        for i in range(M):\n",
    "            params.emission_matrix[i,:] = [float(x) for x in read_non_comment(f).strip().split()]\n",
    "        \n",
    "        params.beginning_distribution[:] = np.array([float(x) for x in read_non_comment(f).strip().split()])\n",
    "        \n",
    "        return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMM generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import choice as npchoice\n",
    "\n",
    "# params is HMM_Params\n",
    "# returns sequence of tuples: (pi, x)\n",
    "def generate_random_HMM(params):\n",
    "    current_pos = npchoice(params.state_num,1, p=params.beginning_distribution)[0]\n",
    "    current_emission = npchoice(params.emission_num, 1, p=params.emission_matrix[current_pos,:])[0]\n",
    "    result = []\n",
    "    while len(result)<params.observation_length:\n",
    "        result.append((current_pos, current_emission))\n",
    "        current_pos = npchoice(params.state_num, 1, p=params.transition_matrix[current_pos,:])[0]\n",
    "        current_emission = npchoice(params.emission_num, 1, p=params.emission_matrix[current_pos,:])[0]\n",
    "    return result\n",
    "\n",
    "def beautify_HMM_sequence(hmm_seq):\n",
    "    def beautify_pair(p):\n",
    "        return 'p%d'%p[0], 'e%d'%p[1]\n",
    "    return [beautify_pair(x) for x in hmm_seq]\n",
    "\n",
    "def print_HMM_to_file(hmm, filename):\n",
    "    hmm = beautify_HMM_sequence(hmm)\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write('\\n'.join(map(lambda p:'%s\\t%s'%p, hmm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = read_params('test.txt')\n",
    "hmm = generate_random_HMM(params)\n",
    "print_HMM_to_file(hmm, 'generated_path.txt')\n",
    "#beautify_HMM_sequence(hmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input is HMM_Params and observation list (with ints inside)\n",
    "# output is hidden states in integer list\n",
    "def viterbi_solver(params, observations):\n",
    "    # matrix LxM where stored previous states for each state in row\n",
    "    parents = np.zeros((params.observation_length, params.state_num), dtype='float64')\n",
    "    # current probabilities\n",
    "    current_iter = np.log(params.beginning_distribution) + np.log(params.emission_matrix[:,observations[0]])\n",
    "    # probabilities of next step\n",
    "    next_generation = np.zeros(params.state_num,dtype='float64')\n",
    "    for i in range(1, params.observation_length):\n",
    "        for state in range(params.state_num):\n",
    "            probs = current_iter + np.log(params.transition_matrix[:,state])\n",
    "            prev = probs.argmax()\n",
    "            next_generation[state] = probs[prev] + np.log(params.emission_matrix[state, observations[i]])\n",
    "            parents[i,state] = prev\n",
    "        # avoid garbage collection\n",
    "        current_iter, next_generation = next_generation, current_iter\n",
    "    \n",
    "    path = np.ones(params.observation_length, dtype='int64')\n",
    "    path[-1] = current_iter.argmax()\n",
    "    for i in range(params.observation_length - 2, -1, -1):\n",
    "        p = parents[i+1, path[i+1]]\n",
    "        path[i] = p\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.680000\n"
     ]
    }
   ],
   "source": [
    "# checking viterbi\n",
    "params = read_params('test.txt')\n",
    "data = [x.strip() for x in open('generated_path.txt', 'r')]\n",
    "observations = [int(x.split()[1][1:]) for x in data]\n",
    "actual_states = [int(x.split()[0][1:]) for x in data]\n",
    "most_probable = viterbi_solver(params, observations)\n",
    "with open('viterbi.txt', 'w') as f:\n",
    "    f.write(\"RPath\\tObserv\\tViterbi\\n\")\n",
    "    p = map(lambda x: '%s\\tp%d'%x, zip(data, most_probable))\n",
    "    p = list(p)\n",
    "    f.write('\\n'.join(p))\n",
    "same_indices = [i for i in range(len(data)) if actual_states[i]==most_probable[i]]\n",
    "print(\"Accuracy: %f\"%(len(same_indices)/len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp\n",
    "\n",
    "# returns 3 elems: \n",
    "#  terminating probability, \n",
    "#  list of logs of probability of subsequence from start to index\n",
    "#  and the matrix for posterior\n",
    "def forward_algorithm(params, observations):\n",
    "    observe_len = len(observations)\n",
    "    prob_matrix = np.zeros((observe_len+1, params.state_num), dtype='float64')\n",
    "    prob_matrix[-1,:] = np.log(1/params.state_num) # initial state\n",
    "    for i in range(observe_len):\n",
    "        for nxt in range(params.state_num):\n",
    "            probs = np.log(params.transition_matrix[:,observations[i]]) + prob_matrix[i-1,:]\n",
    "            prob_matrix[i, nxt] = np.log(params.emission_matrix[nxt, observations[i]]) + logsumexp(probs)\n",
    "    res = logsumexp(prob_matrix[:observe_len,:], axis=1)\n",
    "    return np.exp(res[-1]), res, prob_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.323044134971431e-59"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob, _, matr = forward_algorithm(params, observations)\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns 3 elems: \n",
    "#  terminating probability, \n",
    "#  log of terminating probability\n",
    "#  and the matrix for posterior\n",
    "def backward_algorithm(params, observations):\n",
    "    observe_len = len(observations)\n",
    "    matrix = np.zeros((observe_len, params.state_num), dtype='float64')\n",
    "    matrix[-1,:] = 1\n",
    "    for i in range(observe_len-2, -1, -1):\n",
    "        for prev in range(params.state_num):\n",
    "            probs = np.log(params.transition_matrix[prev,:])+\\\n",
    "                    np.log(params.emission_matrix[:,observations[i+1]])+\\\n",
    "                    matrix[i+1,:]\n",
    "            matrix[i, prev] = logsumexp(probs)\n",
    "    probs = np.log(params.transition_matrix[0,:])+\\\n",
    "                    np.log(params.emission_matrix[:,observations[0]])+\\\n",
    "                    matrix[0,:]\n",
    "    res = logsumexp(probs)\n",
    "    return np.exp(res), res, matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.912414713862639e-59"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backward_algorithm(params, observations)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns probabilities for each state in each iteration\n",
    "# iteration is row, state is column\n",
    "def posterior_decoding(params, observations):\n",
    "    probability, prob_log, forward_matr = forward_algorithm(params, observations)\n",
    "    backward_prob, back_log, backward_matr = backward_algorithm(params, observations)\n",
    "    out_probs = np.zeros((len(observations), params.state_num), dtype='float64')\n",
    "    for i in range(len(observations)):\n",
    "        out_probs[i, :] = forward_matr[i, :] + backward_matr[i,:] - prob_log[i]\n",
    "    out_probs = np.exp(out_probs)\n",
    "    # even if it not described in lecture, I suppose that probabilities need to be normalized for use\n",
    "    for i in range(len(observations)):\n",
    "        out_probs[i,:] /= np.sum(out_probs[i,:])\n",
    "    return out_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.18502823, 0.81497177],\n",
       "       [0.19278511, 0.80721489],\n",
       "       [0.22269793, 0.77730207],\n",
       "       [0.3327689 , 0.6672311 ],\n",
       "       [0.67701541, 0.32298459],\n",
       "       [0.18641749, 0.81358251],\n",
       "       [0.19818587, 0.80181413],\n",
       "       [0.24318157, 0.75681843],\n",
       "       [0.40363797, 0.59636203],\n",
       "       [0.85869947, 0.14130053]])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior_decoding(params, np.array(observations))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unfair casino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
